# さまざまな LLM の調査と比較

[![Exploring and comparing different LLMs](../../images/02-lesson-banner.png?WT.mc_id=academic-105485-yoterada)](https://youtu.be/J1mWzw0P74c?WT.mc_id=academic-105485-yoterada)

> *(上記の画像をクリックすると、レッスン・ビデオを表示します)*

前回のレッスンで、生成 AI がどのようにして進化し、大規模言語モデル（LLM）がどのように機能するのか、そしてスタートアップがそれらを自分たちの目的に対して、どのように適用し成長できるかを見てきました。この章では、様々な大規模言語モデル（LLM）を比較し、それぞれの利点と欠点を理解していきます。

スタートアップは次に、大規模言語モデル（LLM）の最新状況を調査し、自社のニーズに適したモデルが何かを検討する段階に移りました。

## はじめに

このレッスンでは、下記の内容について説明します。

- いま存在する様々な種類の LLM（大規模言語モデル）について学ぶ
- Azure で用途に応じて異なる AI モデルを選択しテスト、反復作業、及び比較を行う
- LLM のデプロイ方法について学ぶ

## 学習目標

このレッスンを修了すると、下記を理解できます：

- ユースケースに適したモデルを選択する
- モデルのパフォーマンスをテストし、反復し、そして改善する方法を理解する
- 企業がどのようにモデルをデプロイするかを知る

## 大規模言語モデル（LLM）の様々な種類の理解

大規模言語モデル（LLM）は、そのアーキテクチャ、トレーニングデータ、用途に応じて、様々なカテゴリに分類できます。こうした各モデルの把握は、スタートアップがシナリオに応じて最適なモデルを選択し、パフォーマンスのテストを行い、反復しながら改善するのに役立ちます。  

LLM モデルには、さまざまな種類があり、どのモデルを選択するかは、それらを使用する目的、扱うデータ、ご利用可能な金額などによって異なります。  

選択するモデルは、テキスト、オーディオ、ビデオ、画像の生成など、各用途に応じてそれぞれ異なる種類のモデルを選択します。

- **オーディオおよび音声認識** この用途には、音声認識として汎用性のある Whisper というモデルが最適です。このモデルは、様々なオーディオ・データでトレーニングされており、多言語にも対応した音声認識ができます。[Whisper のモデルについての詳細はこちら](https://platform.openai.com/docs/models/whisper?WT.mc_id=academic-105485-yoterada).

- **画像生成**。画像生成の選択肢としては、DALL-E と Midjourney が非常に有名です。Azure OpenAI 上で DALL-E のモデルが利用可能です。[DALL-Eについての詳細はこちら](https://platform.openai.com/docs/models/dall-e?WT.mc_id=academic-105485-yoterada)をご覧ください。このカリキュラムの第 9 章でも解説します。

- **テキスト生成**。多くのモデルがテキスト生成用にトレーニングされており、GPT-3.5 から GPT-4 に至るまで、多種多様な選択肢があります。それぞれ利用する際のコストは異なり、GPT-4 が最も高価です。機能とコストの観点から、ニーズに最も適したモデルを選択するために、[Azure OpenAI プレイグラウンド](https://oai.azure.com/portal/playground?WT.mc_id=academic-105485-yoterada)をご確認ください。

モデルを選択すると、基本的な機能を手に入れ、モデルを利用できるようになっていますが、それだけでは不十分な場合もあります。通常、会社固有のデータを何らかの方法で LLM に伝えなければならない場合もあります。その方法はいくつかの選択肢がありますが、それについては後続のセクションで詳しく説明します。

### ファウンデーション・モデルと LLM の比較

「ファウンデーション・モデル」という用語はスタンフォード大学の研究者たちが提唱し、以下のような基準に従う AI モデルとして定義しています。

- **教師なし学習、または自己教師あり学習でトレーニング** ラベルのないマルチモーダル・データを用いてトレーニングし、トレーニング・プロセス中、人間によるデータの注釈やラベル付けは不要です
- **非常に大規模なモデル**。数十億のパラメーターを用いてトレーニングされたディープ・ニューラル・ネットワークに基づいています
- **通常、他のモデルの「基盤」として機能** ファイン・チューニングを行い、他のモデルを構築する際の基盤として使用できます

![ファウンデーション・モデルと LLM](../../images/FoundationModel.png?WT.mc_id=academic-105485-yoterada)

画像出展: [基盤モデルと大規模言語モデルの効果的なガイド | Babar M Bhatti著 | Medium](https://thebabar.medium.com/essential-guide-to-foundation-models-and-large-language-models-27dab58f7404)

この違いをさらに明確にするために、ChatGPT を例に挙げてみましょう。ChatGPT の最初のバージョンを作る際 GPT-3.5 というモデルをファウンデーション・モデルとして使いました。つまり、OpenAI は、チャットボットのような会話シナリオで高いパフォーマンスを発揮するよう、チャットに特化したデータを用いて GPT-3.5 のチューニング版を作成したのです。

![Foundation Model](../../images/Multimodal.png?WT.mc_id=academic-105485-yoterada)

画像出展: [2108.07258.pdf (arxiv.org)](https://arxiv.org/pdf/2108.07258.pdf?WT.mc_id=academic-105485-yoterada)

### オープンソース・モデルとプロプライエタリ・モデル  

大規模言語モデル（LLM）を分類する別の方法として、それがオープンソースなのか、それともプロプライエタリのものなのか、という観点があります。  

オープンソース・モデルは、一般に公開され、誰でも利用できるモデルです。これらは多くの場合、そのモデルを開発した企業や研究コミュニティによって提供されます。これらのモデルは、LLM の様々な用途に合わせて検証、変更、カスタマイズの許可がされています。しかし、常に本番環境での利用に最適化されているわけではなく、プロプライエタリモデルほど高いパフォーマンスを発揮しない場合もあります。さらに、オープンソース・モデルの資金調達は限られており、長期的に継続できない場合や、最新の研究に基づいて更新されない可能性もあります。[Alpaca](https://crfm.stanford.edu/2023/03/13/alpaca.html?WT.mc_id=academic-105485-yoterada)、[Bloom](https://sapling.ai/llm/bloom?WT.mc_id=academic-105485-yoterada)、[LLaMA](https://sapling.ai/llm/llama?WT.mc_id=academic-105485-yoterada) などが人気のオープンソース・モデルの例です。

プロプライエタリ・モデルは、企業が所有し一般には公開されていないモデルです。これらのモデルは、通常本番環境での利用に最適化されています。しかし異なるユースケースに対して、検証、変更、カスタマイズは許されていません。また、常に無料で利用できるわけではなく、利用するためには、サブスクリプションによる支払いが必要な場合もあります。さらに、利用者はモデルをトレーニングする際に使用するデータをコントロールできず、データのプライバシーや、責任ある AI の原則に基づく使用をモデル・プロバイダが保証しているのを信用しなければなりません。[OpenAI のモデル](https://platform.openai.com/docs/models/overview?WT.mc_id=academic-105485-yoterada)、[Google Bard](https://sapling.ai/llm/bard?WT.mc_id=academic-105485-yoterada)、[Claude 2](https://www.anthropic.com/index/claude-2?WT.mc_id=academic-105485-yoterada) などが人気のプロプライエタリ・モデルです。

### 埋め込み (Embedding) と画像生成とテキスト・コード生成  

大規模言語モデル(LLM) は出力の種類によっても分類できます。  

埋め込み (Embedding) は、テキストを、埋め込みと呼ぶ、数値形式に変換する AI モデルです。言い換えるならば、埋め込みは入力されたテキストに対する数値表現です。埋め込みによって、機械が単語や文の関係を理解しやすくなり、分類モデルや、数値データでパフォーマンスが向上するクラスタリング・モデルなど、他のモデルの入力として利用できます。埋め込みモデルは、データが豊富な代理タスクのためにモデルを構築し、その後でモデルの重み（埋め込み）を他の下流タスクで再利用する転移学習によく使用されます。このカテゴリーの例としては、[OpenAI Embeddings](https://platform.openai.com/docs/models/embeddings?WT.mc_id=academic-105485-yoterada) モデルがあります。

![Embedding](../../images/Embedding.png?WT.mc_id=academic-105485-yoterada)

画像生成モデルは、画像を生成するモデルです。これらのモデルは、画像編集、画像合成、画像変換で頻繁に利用されます。画像生成モデルは、[LAION-5B](https://laion.ai/blog/laion-5b/?WT.mc_id=academic-105485-yoterada) などの大規模な画像データセットでトレーニングするのが多く、新しい画像を生成したり、画像修復、高解像度化、色付け技術を用いて既存の画像を編集する際に利用できます。[DALL-E-3](https://openai.com/dall-e-3?WT.mc_id=academic-105485-yoterada) や [Stable Diffusion models](https://github.com/Stability-AI/StableDiffusion?WT.mc_id=academic-105485-yoterada) といったモデルがあります。

![Image generation](../../images/Image.png?WT.mc_id=academic-105485-yoterada)

テキスト生成モデルとコード生成モデルは、テキストやコードを生成するモデルです。これらのモデルは、テキストの要約、翻訳、質疑応答などによく利用されます。テキスト生成モデルは、[BookCorpus](https://www.cv-foundation.org/openaccess/content_iccv_2015/html/Zhu_Aligning_Books_and_ICCV_2015_paper.html?WT.mc_id=academic-105485-yoterada) などの大規模なテキストデータセットでトレーニングされ、新しいテキストを生成したり、質問に答えたりするのに使われます。[CodeParrot](https://huggingface.co/codeparrot?WT.mc_id=academic-105485-yoterada) のようなコード生成モデルは、GitHub などの大規模なソースコード・データセットでトレーニングされ、新しいコードを生成したり、既存コードのバグ修正に使われます。
 ![Text and code generation](../../images/Text.png?WT.mc_id=academic-105485-yoterada)

### 「エンコーダー・デコーダー」 と 「デコーダーのみ」 のモデル

大規模言語モデル (LLM) のアーキテクチャの種類の違いについて解説するため、下記の例え話しを使います。  

上司から、学生用のクイズを作成する仕事を任されたのを想像してください。あなたには 2 人の同僚がいて、1 人はコンテンツの作成を担当し、もう 1 人はそれをレビューする役割を担います。  

コンテンツを作成する人は「デコーダーのみ」のモデルに似ています。コンテンツ作成者は、トピックを見て、既に書いた内容を参考に、それに基づいてコンテンツを作成します。コンテンツ作成者は、魅力的で情報豊かなコンテンツを作成するのが得意ですが、トピックや学習目標を理解するのは得意ではありません。「デコーダーのみ」のモデルの例には、GPT-3 などの GPT ファミリーのモデルがあります。  

一方で、レビューを担当する人は「エンコーダーのみ」のモデルに似ています。レビュー担当者は書かれたコンテンツと回答を見て、それらの関係を把握し、文脈を理解しますが、コンテンツを作成するのは得意ではありません。「エンコーダーのみ」のモデルの例には、BERT があります。  

クイズを作成し、それをレビューする同一人物がいるのを想像してみてください。これが「エンコーダー・デコーダー」モデルです。BARTやT5などが例として挙げられます。

### サービスとモデル

サービスとモデルの違いについて説明します。サービスはクラウド・サービス・プロバイダーが提供する製品で、モデル、データ、その他のコンポーネントを組み合わせたものです。モデルはサービスの核となる部分で、大規模言語モデル (LLM) のようなファウンデーション・モデルが一般的です。  

サービスは、本番環境での利用に最適化されており、グラフィカル・ユーザー・インターフェースを通じて、直接モデルを操作するのに比べ扱いやすいです。しかしサービスは、常に無料で利用できるわけではなく、サービス提供者の機器やリソースを活用する代わりに、サブスクリプションや支払いが必要な場合があります。これにより、費用を最適化し、簡単にスケールアップできます。サービスの例としては、使用量に応じて料金が発生する [Azure OpenAI Service](https://learn.microsoft.com/azure/ai-services/openai/overview?WT.mc_id=academic-105485-yoterada) があります。また、Azure OpenAI サービスは、モデルの能力に加えて、エンタープライズグレードのセキュリティと責任あるAIフレームワークを提供します。  

モデルは、パラメーターや重みなどを含むニューラルネットワークそのものです。企業はローカルでの運用も可能ですが、そのためには機器の購入、スケールアップのための環境構築、ライセンスの購入、またはオープンソース・モデルの使用が必要になります。LLaMAのようなモデルは利用可能ですが、モデルを実行するための計算能力が必要です。

## Azure でパフォーマンスを理解するために異なるモデルでテストと反復処理を行う方法  

現在の LLM の状況を調査し、シナリオに適したモデルの候補を見つけたら、次に企業の実データと負荷試験でそれらをテストする必要があります。これは実験と測定を通じて行われる反復的なプロセスです。前の段落で触れたモデル（OpenAIモデル、Llama2のようなオープンソースモデル、Hugging Faceのトランスフォーマー）のほとんどは、[Azure Machine Learning Studio](https://ml.azure.com/?WT.mc_id=academic-105485-yoterada) の[ファウンデーション・モデル・カタログ](https://learn.microsoft.com/azure/machine-learning/concept-foundation-models?WT.mc_id=academic-105485-yoterada)で利用可能です。  

[Azure Machine Learning](https://azure.microsoft.com/products/machine-learning/?WT.mc_id=academic-105485-yoterada) は、データ・サイエンティストと機械学習エンジニアが ML ライフサイクル全体（トレーニング、テスト、デプロイ、MLOpsの管理）を一つのプラットフォームで管理するために設計されたクラウド・サービスです。Machine Learning Studio はグラフィカル・ユーザー・インターフェースを提供し、ユーザーは下記の操作を行えます：

- カタログから興味のあるファウンデーション・モデルを探し、タスク、ライセンス、名前でフィルタリングします。カタログにまだ含まれていない新しいモデルもインポートできます。
- モデル・カードを確認して、詳細な説明とコードサンプルを見て、サンプル推論ウィジェットを使ってテストします。これは、サンプルプロンプトを提供して結果を試すものです。

![Model card](../../images/Llama1.png?WT.mc_id=academic-105485-yoterada)

- 特定の負荷試験と入力された特定のデータセットに関する客観的な評価指標を用いて、モデルのパフォーマンスを評価します。

![Model evaluation](../../images/Llama2.png?WT.mc_id=academic-105485-yoterada)

- Azure Machine Learning の実験と追跡機能を活用して、カスタム・トレーニングデータでモデルをファイン・チューニングし、特定の負荷試験におけるモデルのパフォーマンスを向上させます。

![Model fine-tuning](../../images/Llama3.png?WT.mc_id=academic-105485-yoterada)

- 元の事前トレーニング済みモデルまたはファイン・チューニングされたバージョンをリモートのリアルタイム推論、もしくはバッチ・エンドポイントにデプロイし、アプリケーションから利用できるようにします。

![Model deployment](../../images/Llama4.png?WT.mc_id=academic-105485-yoterada)

## 大規模言語モデル (LLM) の出力結果を改善する

スタートアップ・チームは、さまざまな種類の大規模言語モデル (LLM) とクラウド・プラットフォーム（Azure Machine Learning）を理解し、異なるモデルを比較し、テストデータで評価し、パフォーマンスを向上させ、推論エンドポイントにデプロイする方法を検討しました。  

しかし、事前トレーニングされたモデルを使用するのではなく、モデルをファイン・チューニングするのを検討すべきタイミングはいつでしょうか？特定の負荷試験でモデルのパフォーマンスを向上させる他のアプローチはあるのでしょうか？  

企業が LLM から必要な結果を得るためには、トレーニング程度の異なる様々な種類のモデルを選択するなど、いくつかのアプローチがあります。  

異なるレベルの複雑さ、コスト、品質で LLM を本番環境にデプロイできます。以下に、いくつかの異なるアプローチを紹介します。

- **コンテキストを用いたプロンプトエンジニアリング** プロンプトを記述する際に十分なコンテキストを提供し、必要な回答を得るのが狙いです。  

- **Retrieval Augmented Generation（RAG）** 例えば、データがデータベースや Web 上に存在する場合、プロンプトの記述時に、それらのデータや一部を含めるために、関連データを取得し、プロンプトの一部にできます。  

- **ファイン・チューニングしたモデル** 自分のデータを利用してモデルをさらにトレーニングし、モデルをより正確に、そしてニーズに応じた形にします。ただし、コストがかかる可能性があります。

![LLMs deployment](../../images/Deploy.png?WT.mc_id=academic-105485-yoterada)

画像出展:: [Four Ways that Enterprises Deploy LLMs | Fiddler AI Blog](https://www.fiddler.ai/blog/four-ways-that-enterprises-deploy-llms?WT.mc_id=academic-105485-yoterada)

### コンテキストを用いたプロンプトエンジニアリング  

事前学習済みの LLM は、一般的な自然言語タスクとして、短いプロンプトで文章を作成するか、問い合わせ内容を作成して呼び出すとうまく動作します。これを「ゼロショット」学習と言います。  

しかし、詳細なリクエストとサンプルを用いて問い合わせ内容を記述すると、つまり追加のコンテキストを提供すると、回答はより正確でユーザーの期待値に近いものになります。この場合、プロンプトに一つの例が含まれている場合は「ワンショット」学習、複数の例が含まれていると「フュー・ショット」学習と言います。コンテキストを用いたプロンプト・エンジニアリングは、始めに実施すべきで、そして最もコスト効率の高いアプローチです。

### Retrieval Augmented Generation（RAG）

LLM は、トレーニング中に使用したデータだけを使って回答を作るという制約があります。これは、トレーニングプロセス後に起こった事実について何も知らず、非公開情報 (企業データなど) にもアクセスできません。しかし、このような制約は、プロンプトの長さ制限を考慮しつつ、外部データであるドキュメントの一部をプロンプト内に含める RAG と呼ぶ技術で対応できます。RAG は、Vector データベース （[Azure AI Search](https://learn.microsoft.com/azure/search/vector-search-overview?WT.mc_id=academic-105485-yoterada) など）でサポートされており、さまざまな定義済みのデータ・ソースから有用なドキュメントの一部を取得し、プロンプトのコンテキスト（文脈）に含めて、より正確な回答を得られるようになります。

この技術は、LLM をファイン・チューニングするための十分なデータや、時間、リソースがない企業にとって非常に有用です。そして特定の負荷試験におけるパフォーマンスを向上させ、回答の捏造リスク、つまり現実の歪曲や有害なコンテンツのリスクを減らしたい場合に非常に有効です。

### ファイン・チューニングしたモデルの利用  

ファイン・チューニングは、転移学習を活用してモデルを下流タスクに「適応」させたり、特定の問題を解決するプロセスです。フュー・ショット学習や、RAG とは異なり、更新した重みとバイアスを持つ新しいモデルを生成します。これには、プロンプト（入力）とそれに関連する出力（完成）からなるトレーニング・サンプルが必要です。このアプローチが好まれるのは以下のような場合です：

- **ファイン・チューニングしたモデルを使用する場合** 企業が高性能なモデルではなく、ファイン・チューニングした能力の低いモデル（埋め込みモデルなど）を使用し、よりコスト効率を高く、迅速なソリューション提供したいと考えている場合  

- **レイテンシーを考慮する場合** 特定の用途でレイテンシーが重要で、とても長いプロンプトを使用できない、またはモデルから学習するサンプル数がプロンプトの長さ制限に合わない場合  

- **最新の状態を維持する場合** 企業が高品質のデータと正確なラベルを多く持ち、これらのデータを時間をかけて最新の状態に保つためにリソースを持っている場合

### トレーニング済みモデル  

LLM をゼロからトレーニングするのは、間違いなく最も困難で最も複雑なアプローチです。膨大なデータ、熟練したリソース、適切な計算能力が必要です。このオプションは、ビジネスがドメイン固有のユースケースと大量のドメイン中心のデータを持っている場合にのみ検討すべきです。

## 知識チェック  

LLM からの出力結果を改善するための良いアプローチは何でしょうか？  

1. コンテキストを用いたプロンプトエンジニアリング  
2. RAG  
3. 微調整されたモデル  

A: 3、時間とリソース、高品質のデータがある場合、微調整は最新の状態を維持するためのより良い選択肢です。しかし、改善を目指していて時間が足りない場合は、まず RAG を検討する価値があります。  

## 🚀 Challenge

ビジネスで RAG を活用する方法についてもっと学びたい方は、[こちら](https://learn.microsoft.com/azure/search/retrieval-augmented-generation-overview?WT.mc_id=academic-105485-yoterada)をご覧ください。  

## お疲れ様でした! 次のレッスンを続ける

このレッスン終了後、[生成 AI 学習コレクション](https://aka.ms/genai-collection?WT.mc_id=academic-105485-yoterada)をチェックして、生成 AI の知識をさらに深めましょう。  

次のレッスン 3 では、[責任ある生成 AI の利用](../../../03-using-generative-ai-responsibly/translations/ja-jp/README.md?WT.mc_id=academic-105485-yoterada)について学びます！
