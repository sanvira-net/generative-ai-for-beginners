# プロンプト・エンジニアリングの基礎

[![Prompt Engineering Fundamentals](../../images/04-lesson-banner.png?WT.mc_id=academic-105485-yoterada)](https://youtu.be/r2ItK3UMVTk?WT.mc_id=academic-105485-yoterada)

大規模言語モデル (LLM) では、プロンプトの書き方がとても重要で、慎重に作成したプロンプトは、そうでないものに比べ良い結果をもたらします。しかし、プロンプトやプロンプト・エンジニアリングとは一体どういう物なのでしょうか？また、LLM に送信する内容をどのようにして改善すればいいのでしょうか？この章と次の章では、そうした疑問に答えたいと思います。  

_生成 AI_ は、ユーザーからの依頼に対して、テキスト、画像、オーディオ、コード等の新しいコンテンツを生み出す能力を有しています。これを実現するために、OpenAI の GPT（Generative Pre-trained Transformer）シリーズのような、自然言語とコードの使用目的でトレーニングされた _大規模言語モデル（LLM）_ を利用します。

利用者は、チャットのような馴染み深い手法で、特別な技術の知識や研修を受講しなくても、これらのモデルと対話できるようになります。これらのモデルは、_プロンプト_ で操作し、ユーザーがテキストの入力（プロンプト）をモデルに送信すると、AI モデルからの回答（コンプリーション）が得られます。その後、利用者は何度も 「AI と対話」を重ね、複数回のやり取りを通じてプロンプトを洗練させ、期待する回答が得られるまで調整を行います。

現在、「プロンプト」は生成 AI アプリケーションの主要なプログラミング・インターフェースとなっており、モデルに対して何を行うべきか指示し、そして返される回答の品質にも影響を与えています。「プロンプト・エンジニアリング」は、大規模で一貫性のある高品質な回答を得るためのプロンプトの設計と最適化に焦点を当てた、急速に成長している研究分野です。

## 学習目標

このレッスンでは、プロンプト・エンジニアリングとは何か、そしてその重要性、また特定のモデルやアプリケーションの目的に応じた、効果的なプロンプトの作成方法について学習します。プロンプト・エンジニアリングの基本概念とベスト・プラクティスを理解し、これらを適用している例を、インタラクティブな Jupyter ノートブック「サンドボックス」環境上で動かし、その操作方法も学びます。

このレッスンの終了後、下記ができるようになります：

1. プロンプト・エンジニアリングとは何か、またその重要性について説明できる
2. プロンプトの構成要素とその使用方法について述べる
3. プロンプト・エンジニアリングのベストプラクティスと技術を習得する
4. OpenAI のエンドポイントにアクセスし、学んだテクニックを実際に試す

プロンプト・エンジニアリングは現在、科学というよりは、むしろ芸術に近いものです。これに対する感覚を高めるには、_より多くの練習_ を積み重ね、アプリケーション専門知識で推奨される技術や、モデル固有の最適化を組み合わせた、試行錯誤による検証が重要です。

## サンドボックス (Sandbox) とは

このレッスンに付随する Jupyter ノートブックは、学んだ内容を実際に試せる _サンドボックス_ 環境を提供します。レッスン中、もしくは最終的なコードチャレンジで利用できます。演習を行うためには、下記が必要です：

1. OpenAI API キー - デプロイした大規模言語モデル（LLM）のサービスエンドポイント
2. Python の実行環境 - ノートブックを実行する環境

このリポジトリは、_.devcontainer_ ディレクトリ配下の設定ファイルで Python 3 の実行環境を含むコンテナ・イメージを提供しています。GitHub Codespaces、もしくは Docker Desktop をインストールしたご自身のローカル環境でリポジトリを開き、コンテナ・イメージを自動的に起動します。その後、ノートブックを開いて Python 3.x カーネルを選択すると、実行するノートブックを準備できます。

デフォルトで用意されているノートブックは、OpenAI の API キーを利用する設定になっています。フォルダのルート・ディレクトリにある`.env.copy`を`.env`にリネームし、`OPENAI_API_KEY=`の行に API キーを入力するだけで、準備が完了します。

このノートブックには基本的な演習が用意されていますが、より多くのサンプルやアイディアを試すために、ご自身で _Markdown_（説明文）や _Code_（プロンプトのリクエスト）のセクションを追加できます。これにより、プロンプト・デザインに対する感覚をより養えます。

## スタートアップ

それでは、_このトピック_ がスタートアップのミッションである「[教育へ AI 革新をもたらす](https://educationblog.microsoft.com/2023/06/collaborating-to-bring-ai-innovation-to-education?WT.mc_id=academic-105485-yoterada)」とどのように結びついているのかについて見て行きましょう。私たちは　_個別学習_　を実現する AI アプリケーションの開発を目指しています。そこで、私たちのアプリケーションを利用する様々な利用者がプロンプトをどのように「デザイン」するのかを考えてみましょう。  

- **管理者**: AI に _カリキュラムのデータを分析し、カバーしてない領域を特定する_ よう要求する可能性があります。AI はその結果をまとめたり、コードを用いて可視化できます。
- **教員**: AI に _特定の生徒と授業科目に応じた授業計画の作成を依頼する_ 可能性があります。AI は指定されたフォーマットに従って個別に計画を作成できます。
- **生徒**: AI に _苦手な科目で個別指導を依頼する_ 可能性があります。AI は生徒のレベルに合わせたレッスン、ヒント、例を提供して指導できます。

これらは、ほんの一例です。教育専門家から厳選された、オープンソースのプロンプト・ライブラリ「[Prompts For Education](https://github.com/microsoft/prompts-for-edu/tree/main?WT.mc_id=academic-105485-yoterada)」を確認し、さらに広い視野で可能性を探ってみてください！ _サンドボックスでそれらのプロンプトを試しに実行したり、OpenAI Playground で試してどのような結果が得られるかを試してください！_  

<!--
LESSON TEMPLATE:
このユニットでは、基本となる下記の CONCEPT #1 をカバーするべきです。
例や参照を用いてその概念を強化します。

CONCEPT #1:
プロンプトエンジニアリング
それが何であり、なぜ必要なのかを定義し説明します。
-->

## プロンプト・エンジニアリングとは何ですか？

レッスンの冒頭で、**プロンプト・エンジニアリング**は、特定のアプリケーションとモデルに対して、一貫性があり質の高い回答（コンプリーション）を得るために、テキスト入力（プロンプト）を _設計して最適化する_ 作業と説明しました。これは下記の 2 段階のプロセスとして考えられます。  

- 特定のモデルと目的に合わせた初期プロンプトを _設計する_
- 回答品質を向上させるために、プロンプトを反復して _改善する_  

最適な結果を導き出すためには、ユーザーの勘と努力を要する試行錯誤の過程が必要不可欠です。それがどうして重要なのかというと、その答えを出す前に、我々は下記の 3 つの概念を理解する必要があります。

- _Tokenization_ = モデルがプロンプトを「理解する」方法
- _Base LLM_ = ファウンデーション・モデルがプロンプトを「処理する」方法
- _Instruction-Tuned LLM_ = モデルが「タスク」を理解する方法

### Tokenization

LLM は、プロンプトを _トークンの連続_ として見ており、異なるモデル（またはモデルの異なるバージョン）を利用すると、同じプロンプトでも異なる方法でトークン化する場合があります。LLM は生のテキストではなくトークンを使ってトレーニングしているため、プロンプトがどのようにトークン化されるかは、生成される回答品質に直接影響を及ぼします。

トークン化の仕組みを理解するには、こちらの [OpenAI Tokenizer](https://platform.openai.com/tokenizer?WT.mc_id=academic-105485-yoterada) などのツールを使ってご確認いただくのが良いかもしれません。プロンプトをコピーして、それがどのようにトークンに変換されるかをツールからご確認ください。特に空白文字や句読点の扱いに注意してください。下記の例では、古い LLM（GPT-3）の例を示していますが、新しいモデルを利用すると異なる結果になるかもしれません。

![Tokenization](../../images/04-tokenizer-example.png?WT.mc_id=academic-105485-yoterada)

> 訳者追記：  
> 太陽の 1000 分の 1 の質量を持つ巨大ガス惑星ですが、太陽系の他のすべての惑星を合わせた質量の 2 倍です。木星は、夜空で肉眼で見える天体の中で最も明るい天体の一つで、有史以前から古代文明に知られていました。ローマの神ジュピターにちなんで名付けられました。[19]地球から見ると、木星は反射光が目に見える影を落とすのに十分な明るさであり[20]、夜空では月と金星に次いで平均して 3 番目に明るい天体です。

### 概念: ファウンデーション・モデル

プロンプトをトークンに分割した後、「[Base LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-yoterada)」（またはファウンデーションモデル）は、その分割したトークンの連続した文字列の中で、次に来るトークンは何かを予測します。LLM は膨大な量のテキスト・データでトレーニングされているため、トークン間の統計的な関連性を十分に把握しており、ある程度の自信を持ってその予測を行えます。ただしモデルは、プロンプトやトークンに含まれる単語の「_意味_」 を理解しているわけではなく、次にくるトークンの予測から「完成」できるパターンを単純に見ているだけです。ユーザーが操作を停止するか、あらかじめ定められた条件が満たされるまで、予測を続けます。

プロンプト・ベースの完成 (completion) がどのように機能するか確認したいですか？上記のプロンプトの出力結果をデフォルトの設定のままで Azure OpenAI Studio の[_チャットプレイグラウンド_](https://oai.azure.com/playground?WT.mc_id=academic-105485-yoterada)にコピー＆ペーストしてください。システムは、プロンプトを情報のリクエストとして処理するように構成されいるので、その文脈に適した回答結果が得られるはずです。

それでは、ユーザーがある特定基準やタスク目標に対して適する、特定結果を望む場合はどうでしょうか？そのような場合には、_インストラクション・チューニングされた LLM_ が役立ちます。

![Base LLM Chat Completion](../../images/04-playground-chat-base.png?WT.mc_id=academic-105485-yoterada)

> 訳者追記:  
> はい、その通りです。木星は太陽から 5 番目の惑星であり、太陽系で最大の惑星です。主に水素で構成されており、その質量の 4 分の 1 はヘリウムです。木星の強い内部熱は、雲の帯や、少なくとも 17 世紀から存在がわかっている巨大な嵐である大赤斑など、大気中に多くの半永久的な特徴を生み出します。
木星は、顕著な環（リング）システムと多数の衛星でも知られています。現在、木星の周りを回っている衛星は79個あり、そのうち4個はガニメデ、イオ、エウロパ、カリストです。


### 概念: インストラクション・チューニングされた LLM

[インストラクション・チューニングされた LLM](https://blog.gopenai.com/an-introduction-to-base-and-instruction-tuned-large-language-models-8de102c785a6?WT.mc_id=academic-105485-yoterada) は、ファウンデーションモデルを基に、明確な指示を含む、例や入出力の組み合わせ（例えば、複数回わたる「質問とそれに対する回答例のメッセージ」など）で微調整を施します。すると、AI はその指示に従うような回答作成を試みるようになります。

これには、人間のフィードバックを取り入れた強化学習（Reinforcement Learning with Human Feedback : RLHF）などの技術が使われます。RLHF を利用すると、モデルが利用者からの _指示に従って_ 、 _フィードバックから学習する_ ようにトレーニングでき、これにより、実用的なアプリケーションに適した、よりユーザーの目的に一致する回答が得られるようになります。

それでは、実際に試してみましょう。
先ほどのプロンプトに戻り、今度は _システムメッセージ_ を変更して、下記の指示をコンテキストとして加えてみてください：  

> _提供された内容を小学2年生が理解できるように要約してください。結果は3〜5項目を箇条書きで1段落にまとめてください。_

結果が、期待する内容とフォーマットに合わせて調整されているのをお分かり頂けますか？教員は、この回答を授業のスライドに直接利用できるようになります。  

![Instruction Tuned LLM Chat Completion](../../images/04-playground-chat-instructions.png?WT.mc_id=academic-105485-yoterada)

> 訳者追記：  
> * 木星は太陽から5番目の惑星で、太陽系で最大の惑星です。
> * 太陽よりは軽いのですが、他のすべての惑星を合わせた重量よりも重いガス惑星です。
> * 望遠鏡なしで夜空に木星が見えます、それは本当に明るいです!
> * 惑星はローマの神、Jupiter にちなんで名付けられました。
> * 木星はとても明るく輝いているので、その光は地球に影を落とす場合もあります。通常、夜に月と金星に次いで3番目に明るい星です。


## プロンプト・エンジニアリングはなぜ必要なのでしょうか？  

LLM がプロンプトをどのように処理するかを理解したところで、_なぜ_ プロンプト・エンジニアリングが必要なのかについて考えてみましょう。その答えは、現在の LLM がいくつかの課題を抱えており、プロンプトの作成と最適化に取り組まなければ、_信頼性のある一貫した回答_ を得られず、このような課題が多数存在するという事実があります。例を挙げると：  

1. **モデルの回答は確率的な性質を持っています** たとえ「_同一プロンプト_」でも、異なるモデルやモデルのバージョンの差によって、異なる回答を得る場合があります。そして「_同じモデル_ 」でも、異なる時期に実行すると異なる結果を生じる場合があります。「_プロンプト・エンジニアリングの手法は、より適切なガイドラインを提供し、こうしたばらつきを減らすのに役立ちます。_」

1. **モデルは回答を捏造する場合があります** モデルは「_大規模ながら有限の_」データセットで事前トレーニングされているため、トレーニングの範囲を超える知識は不足しています。その結果、不正確、もしくは架空、あるいは既知の事実と明らかに矛盾する回答を出力する場合があります。「_プロンプトエンジニアリングの手法は、ユーザーがこのような捏造を特定し軽減するのに役立ちます。例えば、AI に出典や論理的根拠の説明を求めて防ぎます。_」

1. **モデルの能力は異なります** 新しいモデルや新世代のモデルは、より高度な機能を持つ一方で、独自の特性やコストと複雑さの面でトレード・オフをもたらします。「_プロンプト・エンジニアリングは、これらの違いを取り除き、スケーラブルでシームレスな方法でモデル固有の要件に適応するベスト・プラクティスとワークフローを開発に役立ちます。_」

OpenAI や Azure OpenAI プレイグラウンドで実際に試してみましょう：  

- 「_異なる_」 LLM 環境（例えば OpenAI、Azure OpenAI、Hugging Face）で同じプロンプトを使って実行してください - 変化に気づきましたか？  
- 「_同じ_」 LLM 環境（例えば：Azure OpenAI プレイグラウンド）で同じプロンプトを繰り返し実行してみてください - これらの変化はどのように変わりましたか？  

### 捏造の例  

この講座では、LLM がトレーニングの制限やその他の制約により、事実に反する情報を回答する現象を「**捏造**」という用語で説明します。一般的な記事や研究論文で「_幻覚_」と表現される場合もありますが、機械が生み出した回答に対して人間の特性を誤って当てはめる擬人化を避けるために、「_捏造_」という用語の使用を強く推奨します。これは、用語の観点から[責任ある AI のガイドライン](https://www.microsoft.com/ai/responsible-ai?WT.mc_id=academic-105485-yoterada)を強化するものであり、また、一部の文脈で不快感を与えたり排他的であると考えられる用語を排除できます。

捏造がどのように行われるかを理解したいですか？AI に対して、トレーニング・データに含まれていない、架空のトピックに関するコンテンツ作成をプロンプトで指示してみてください。例えば、私は下記のプロンプトを試しました：  

> **プロンプト：** 2076年の火星戦争についての授業計画を生成してください。  

Web で検索を行ったところ、火星の戦争についてのフィクション（例：テレビドラマや書籍）はいくつか見つかりましたが、2076 年に関するものは存在しませんでした。常識的に考えても、2076年は「_未来_」であり、実際の出来事との関連付けはできません。  

それでは、このプロンプトを異なる LLM サービス・プロバイダで試したら、どのような結果が得られるのでしょうか？

> **回答 1**: OpenAI Playground (GPT-35)

![Response 1](../../images/04-fabrication-oai.png?WT.mc_id=academic-105485-yoterada)

> **回答 2**: Azure OpenAI Playground (GPT-35)

![Response 2](../../images/04-fabrication-aoai.png?WT.mc_id=academic-105485-yoterada)

> **回答 3**: : Hugging Face Chat Playground (LLama-2)

![Response 3](../../images/04-fabrication-huggingchat.png?WT.mc_id=academic-105485-yoterada)

予想通り、モデルごと（またはモデルのバージョンごと）に、確率的なふるまいやモデルの能力差によって、微妙に異なる回答が得られました。たとえば、一つのモデルは中学 2 年生を対象に回答しているのに対し、別のモデルは高校生を対象に回答しています。しかし、どのモデルも、情報を全く持たない利用者に対して、その出来事が実際にあったかのように誤解生じさせる回答を生成しました。

「_メタプロンプティング_ 」や「_温度調整_」といったプロンプトエンジニアリングの手法は、モデルによる捏造をある程度抑制できます。新しいプロンプト・エンジニアリングの「_アーキテクチャ_」は、これらの影響を緩和または削減させるために、新しいツールや手法をプロンプト・フローにシームレスに取り入れています。

## ケーススタディ：GitHub Copilot  

このセクションを終えるにあたり、[GitHub Copilot](https://github.com/features/copilot?WT.mc_id=academic-105485-yoterada) の事例を通じて、プロンプト・エンジニアリングが実際のソリューションでどのように活用されているかを具体的に見ていきましょう。

GitHub Copilotは「AI ペア・プログラマー」として機能し、開発環境（例：Visual Studio Code）に統合し、テキスト・プロンプトからコードに変換するなどユーザーにシームレスな体験を提供します。下記のブログ・シリーズに記述されているように、初期バージョンは OpenAI Codex モデルをベースにしていました。しかしエンジニアはすぐにコード品質をより向上させるため、モデルをファイン・チューニングし、より良いプロンプト・エンジニアリング技術を開発する必要性を認識しました。7月には、[Codex を越える改良版 AI モデルを発表し](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-yoterada)、これにより、さらに素早い提案が可能になりました。

投稿を順番に読んで、GitHub Copilot の学習の過程をたどってください。

- **2023年5月** | [GitHub Copilot、コード理解能力を向上](https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/?WT.mc_id=academic-105485-yoterada)
- **2023年5月** | [GitHub の内部：GitHub Copilot の背後にある LLM との連携](https://github.blog/2023-05-17-inside-github-working-with-the-llms-behind-github-copilot/?WT.mc_id=academic-105485-yoterada).
- **2023年6月** | [GitHub Copilot 用のより効果的なプロンプトの作成方法](https://github.blog/2023-06-20-how-to-write-better-prompts-for-github-copilot/?WT.mc_id=academic-105485-yoterada).
- **2023年7月** | [改良した AI モデルで Codex を超越した GitHub Copilot](https://github.blog/2023-07-28-smarter-more-efficient-coding-github-copilot-goes-beyond-codex-with-improved-ai-model/?WT.mc_id=academic-105485-yoterada)
- **2023年7月** | [開発者向けプロンプト・エンジニアリングと LLM のガイド ](https://github.blog/2023-07-17-prompt-engineering-guide-generative-ai-llms/?WT.mc_id=academic-105485-yoterada)
- **2023年9月** | [企業向け LLM アプリの構築方法：GitHub Copilot の事例から学ぶ](https://github.blog/2023-09-06-how-to-build-an-enterprise-llm-application-lessons-from-github-copilot/?WT.mc_id=academic-105485-yoterada)

また、これらのモデルやテクニックを実際のアプリケーションに適用する方法をまとめた[こちらの記事](https://github.blog/2023-09-27-how-i-used-github-copilot-chat-to-build-a-reactjs-gallery-prototype/?WT.mc_id=academic-105485-yoterada)のように、
より多くの知見を得たい場合は、[エンジニア・ブログ](https://github.blog/category/engineering/?WT.mc_id=academic-105485-yoterada)もどうぞご覧ください。

---

<!--
LESSON TEMPLATE:
このユニットでは、下記の基本となる CONCEPT #2 を取り扱うべきです。
例や参照を用いてその概念を強化します。

CONCEPT #2:
プロンプトデザイン
例を用いて説明します
-->

## プロンプトの組み立て

ここまで、プロンプト・エンジニアリングがなぜ大切なのかを見てきました。次に、プロンプトをどのようにして「_作成する_」のかを把握し、より効果的なプロンプトを設計するための、様々な手法を見ていきましょう。

### 基本的なプロンプト  

基本的なプロンプトから始めましょう：モデルに送信するテキスト入力で、他のコンテキストはありません。例を挙げると、OpenAI の[Completion API](https://platform.openai.com/docs/api-reference/completions?WT.mc_id=academic-105485-yoterada) にアメリカ国歌の最初の数語を送ると、すぐに次の数行で回答を _完成させる_、基本的な予測動作を行います。  

| プロンプト (入力) | 回答 (出力) |
|:---|:---|
| Oh say can you see | アメリカ合衆国の国歌「星条旗」の歌詞から始めているように聞こえますね。完全な歌詞は... |

### 複雑なプロンプト

次に、基本的なプロンプトにコンテキストと指示を加えてみましょう。[Chat Completion API](https://learn.microsoft.com/azure/ai-services/openai/how-to/chatgpt?WT.mc_id=academic-105485-yoterada) を利用する際、以下の要素をメッセージに含め、高度なプロンプトを作成できます：

- 「_ユーザー_」の入力(質問)と「_アシスタント_」からの回答例を含む入出力ペア
- 「_システムメッセージ_」：アシスタントの振る舞いや、人格のコンテキストを設定

実際のリクエストは下記のようになります。トークン化によってシステム・コンテキストと会話履歴から関連情報を効果的に捉えられるようになります。システム・コンテキストの変更は、ユーザーの入力内容と同じくらい、回答品質に影響を与える可能性があります。

```python
response = openai.ChatCompletion.create(
    model="gpt-3.5-turbo",
    messages=[
        {"role": "system", "content": "あなたは頼りになる助手です。"},
        {"role": "user", "content": "2020年のワールドシリーズで優勝したのはどのチームですか？"},
        {"role": "assistant", "content": "2020年のワールドシリーズはロサンゼルス・ドジャースが優勝しました。"},
        {"role": "user", "content": "その試合はどこでプレイされましたか？"}
    ]
)
```

### 指示 (Instruction) を含むプロンプト

上記の例では、ユーザーのプロンプトは情報を求めるだけの単純なテキストの問い合わせでした。 _指示 (Instruction)_ を含むプロンプトを使用すると、テキストを通じてより詳細にタスクを指定し、AI に対する指示を改善できます。以下に例を示します：

| プロンプト (入力) | 回答 (出力) | 指示 (Instruction) の型 |
|:---|:---|:---|
| 南北戦争について教えてください | _単純な説明文を返す_ | シンプル|
| 南北戦争について教えてください。戦争における重要な日付とその出来事、そしてその重要性を教えてください。 | _説明段落の後に、主要なイベントの日付リストとイベント名、それに関する説明が箇条書きで出力されます。_| 複雑  |
| 南北戦争について1段落で説明を書いてください。戦争における重要な日付とその重要性を3つの箇条書きにしてください。さらに、主要な歴史上の人物とその貢献について3つの箇条書きで記述してください。出力は JSON フォーマットとして返してください。| _テキスト・ボックス内でより詳細な情報を返し、必要に応じてファイルにコピー＆ペーストして検証できるように JSON 形式で整形されたデータを提供します_| 複雑、出力フォーマット指定 |

## 主要コンテンツ

上記の例では、プロンプトは比較的自由度が高く、LLM が事前にトレーニングされたデータセットのどの部分が関連するかを決定する余地がありました。_主要コンテンツ_ のデザイン・パターンでは、入力テキストは二つのパートに分割されます：

- 指示（行動）
- 関連する内容（行動に影響を及ぼす）

以下は、「これを 2 つの短い文にまとめてください」という指示の例です。  

| プロンプト (入力) | 回答 (出力) |
|:---|:---|
| 木星は太陽から五番目の惑星で、太陽系で最も大きな惑星です。質量は太陽の千分の一ですが、太陽系内の他のすべての惑星を合わせたものの2.5倍の巨大ガス惑星です。木星は夜空に肉眼で見える最も明るい天体の一つで、記録された歴史以前から古代文明に知られていました。ローマ神話の神ジュピターにちなんで名付けられました。[19] 地球から見ると、木星は反射光が目に見える影を投げるほど明るくなる場合があり[20]、平均して月と金星に次いで夜空で三番目に明るい天体です。<br/> **これを2つの短い文にまとめてください**| 木星は太陽系で最も大きい惑星で、太陽系の他の全惑星の質量合計の2.5倍に相当します。夜空で3番目に明るく輝くこの巨大ガス惑星は、古代から知られ、ローマ神話の最高神ジュピターの名を冠しています。 |

主要コンテンツの部分は、より効果的な指示を出すためにさまざまな方法で利用できます：

- **実例** - モデルに明確な指示を出す代わりに、実行すべき実例を与えて、そのパターンを推測させます。
- **キュー(手がかり)** - 完了を促す「キュー（合図）」の指示に従って、モデルをより関連性の高い回答に誘導します。
- **テンプレート** - 繰り返し再利用できるプロンプトの「レシピ」で、特定の用途に合わせて入力データをカスタマイズできるプレースホルダー（変数）を持ちます。

これらを実際により詳しく見ていきましょう。  

### 使用例

この手法では、特定の指示に対して期待する出力のサンプルをいくつか「モデルに提供し」、主要コンテンツを使用し、期待する出力パターンをモデルに推測させるアプローチです。提供する例の数に応じて、ゼロショット、ワンショット、フューショット・プロンプティングなどがあります。  

プロンプトは、下記の３つの要素から構成されます：  

- タスクの説明  
- 期待する出力の数例  
- 新しい問い合わせの開始部分（これが暗黙的にタスク説明となります）  

| 学習の型 | プロンプト (入力) | 回答 (出力) |
|:---|:---|:---|
| ゼロ・ショット  | 「太陽は輝いている」をスペイン語に翻訳してください | "El Sol está brillando".|
| ワン・ショット | 「太陽は輝いている」 => "El Sol está brillando". <br> "寒くて風の強い日です" => | "Es un día frío y ventoso". |
| フュー・ショット| プレーヤーは塁を回った => 野球  <br/> プレーヤーはサービス・エースと取った => テニス  <br/> プレーヤーは6ランを打った => クリケット  <br/> プレーヤーはスラムダンクをした => | バスケットボール |
| | | |

ゼロ・ショット・プロンプトでは明示的な指示(「スペイン語に翻訳してください」)を提供する必要がありましたが、ワン・ショット・プロンプトの例では、回答が推測されているのをご確認ください。フュー・ショットの例では、さらに複数の例を追加して、モデルが追加の指示なしで、より正確な推論を行えるようになっているのを示しています。

### プロンプト・キュー

利用者が主要コンテンツにアクセスする際には、実例の代わりに「キュー（手がかり）」を提供する選択肢もあります。この場合、期待する回答フォーマットを反映した一部で「_始めて_」、モデルを正しい方向に誘導します。その後、モデルはその手がかりを受け取って、流れに従って続けます。

| キューの数 | プロンプト (入力) | 回答 (出力) |
|:---|:---|:---|
| 0  | 木星は太陽から五番目の惑星で、太陽系で最も大きな惑星です。質量は太陽の千分の一ですが、太陽系内の他のすべての惑星を合わせたものの2.5倍の巨大ガス惑星です。木星は夜空に肉眼で見える最も明るい天体の一つで、記録された歴史以前から古代文明に知られていました。 <br/>**これを要約してください**  | 木星は太陽系で最も巨大な惑星であり、質量は太陽系の他のすべての惑星の合計の2.5倍に達します。夜空で非常に明るく輝き、古代から人類に認識されていた天体です。|
| 1 | 木星は太陽から五番目の惑星で、太陽系で最も大きな惑星です。質量は太陽の千分の一ですが、太陽系内の他のすべての惑星を合わせたものの2.5倍の巨大ガス惑星です。木星は夜空に肉眼で見える最も明るい天体の一つで、記録された歴史以前から古代文明に知られていました。 <br/>**要約すると、私たちが学んだのは、木星が** <br/> | 太陽系で最も大きい惑星で、太陽から五番目に位置し、質量は太陽系の他の惑星を合わせたものより2.5倍大きいです。また、夜空でよく見える明るい天体の一つで、古代文明の時代から知られています。 |
| 2 | 木星は太陽から五番目の惑星で、太陽系で最も大きな惑星です。質量は太陽の千分の一ですが、太陽系内の他のすべての惑星を合わせたものの2.5倍の巨大ガス惑星です。木星は夜空に肉眼で見える最も明るい天体の一つで、記録された歴史以前から古代文明に知られていました。<br/>**事実から学んだ３つの要約は：** <br/>  | 1. 木星は太陽から五番目の位置にある太陽系で最も大きな惑星です。</br>2. 木星の質量は太陽系の他の惑星を合わせたものよりも2.5倍大きく、太陽の千分の一に相当します。</br>3. 木星は夜空で肉眼によく見える明るい天体であり、古代文明の時代から人類に知られていました。 |
| | | |

### プロンプト・テンプレート

プロンプト・テンプレートは、必要に応じて保存し再利用できる「_事前に定義したプロンプトのレシピ_」で、大規模向けに一貫したユーザー・エクスペリエンスを実現するために使用します。最も基本的な形式は、[OpenAI の例](https://platform.openai.com/examples?WT.mc_id=academic-105485-yoterada)のようなプロンプト例のコレクションで、インタラクティブなプロンプト要素(ユーザー・メッセージとシステム・メッセージ) と API 駆動型のリクエスト・フォーマットの両方を提供しており、再利用を促進しています

[LangChain の例](https://python.langchain.com/docs/modules/model_io/prompts/prompt_templates/?WT.mc_id=academic-105485-yoterada)のような、より複雑な形式では、様々なソース(ユーザー入力、システムコンテキスト、外部データソースなど)からのデータを置き換える _プレースホルダー_ を含んでおり、プロンプトを動的に生成できます。これにより、大規模に「**プログラムによる**」一貫したユーザー・エクスペリエンスを実現するための再利用可能なプロンプトのライブラリを作成できます。

最後に、テンプレートの真の価値は、特定業界 (例、医療、金融、製造など) 用アプリケーションの「_プロンプト・ライブラリ_」を作成し、公開できる点です。プロンプト・テンプレートを、業界に特化したアプリケーション固有のコンテキストや例を反映するように最適化し、ターゲットの利用者にとって回答をより適切で正確なものにします。[Prompts For Edu](https://github.com/microsoft/prompts-for-edu?WT.mc_id=academic-105485-yoterada)は、教育分野に特化したプロンプト・ライブラリを集めたリポジトリで、レッスン計画やカリキュラムの設計、学生の個別指導など、教育関連の重要な項目に焦点を当てたプロンプト・ライブラリを提供する、とても良い例です。  

## サポートコンテンツ

プロンプトの作成を、指示（タスク）と目的（主コンテンツ）を含むものと考えた場合、「_サポートコンテンツ_」は、「**何らかの形で影響を与える**」追加情報のようなものです。これは、モデルがユーザーの目的や期待に応じて回答を _カスタマイズ_ するのを支援するチューニング・パラメーターやフォーマットの指示、トピックの分類方法などを含められます。

例えば、カリキュラムで利用可能な全コースに関する広範囲のメタデータ（名前、説明、レベル、メタデータタグ、講師など）を含むコース・カタログがあるとします：  

- 「2023 年秋のコース・カタログを要約してください」という指示を定義できます  
- プライマリコンテンツを使用して、期待する出力例をいくつか提供できます
- セカンダリコンテンツを使用して、関心のある上位5つの「タグ」を識別できます。

これで、モデルはいくつかの例で示したフォーマットで要約を提供できますが、もし結果に複数のタグが含まれている場合は、セカンダリ・コンテンツで識別した 5 つのタグを優先できます。  

---

<!--
LESSON TEMPLATE:
このユニットでは、下記の基本となる CONCEPT #3 を取り扱うべきです。
例や参照を用いてその概念を強化します。

CONCEPT #3:
プロンプト・エンジニアリングのテクニック
プロンプト・エンジニアリングの基本的なテクニックとは何ですか？
いくつかの練習問題を通じて紹介してください。
-->

## プロンプト作成のベストプラクティス

プロンプトがどのように「_組み立てられる_」かを理解したので、ベスト・プラクティスを反映するように「_プロンプトを設計_」する方法について考えます。これは、適切な「_考え方_」で、適切な「_技術_」を適用するという 2 つの側面に分けて考えられます。  

### プロンプト・エンジニアリングの考え方  

プロンプトエンジニアリングは試行錯誤のプロセスなので、以下の 3 つの広範な指針を念頭に置いてください.

1. **ドメインの理解が大切です。** 回答の精度や関連性は、アプリケーションやユーザーが活動する「_ドメイン（業界・業種・業務）_」に依存します。直感とドメインの専門知識を用いて、**テクニックをさらにカスタマイズ**してください。たとえば、システム・プロンプトに「_ドメイン固有のパーソナリティ_」を定義したり、ユーザー・プロンプトに「_ドメイン固有のテンプレート_」を使用します。ドメイン固有の文脈を反映するセカンダリ・コンテンツを提供したり、「_ドメイン固有の手がかりや例_」を使用して、慣れ親しんだユースケースにモデルを誘導します。

2. **モデル理解が大切です。** モデルは本質的に確率的な性質を持っていますが、使用するトレーニング・データ（事前学習した知識）、提供する機能（例えば API や SDK を通じて）、最適化されたコンテンツの種類（例えばコード、画像、テキスト）によっても実装は異なります。使用するモデルの長所と制限を理解し、その知識を用いて「_タスクに優先順位を付けたり_」、モデルの能力に最適化した「_カスタマイズしたテンプレート_」を作成してください。

3. **反復と検証が重要です。** モデルは急速に進化しており、プロンプト・エンジニアリングの手法も急速に進化しています。ドメインの専門家として、広範囲のコミュニティの中には、 「_あなたが実装したプロンプト_」が適さない場合、つまり独自のコンテキストや基準を持つコミュニティもあるかもしれません。プロンプト・エンジニアリングのツールやテクニックを使用してプロンプトを「いち早く試し」、その後、自分の直感とドメインの専門知識を使用して、結果の検証を繰り返しながら行なってください。そして知見を記録し、他者が将来的により迅速に反復できるよう、そして新基準として再利用できる「**ナレッジベース**（例えばプロンプトライブラリ）」を作成してください。  

## ベストプラクティス

次に、[Open AI](https://help.openai.com/en/articles/6654000-best-practices-for-prompt-engineering-with-openai-api?WT.mc_id=academic-105485-yoterada) と [Azure OpenAI](https://learn.microsoft.com/azure/ai-services/openai/concepts/prompt-engineering#best-practices?WT.mc_id=academic-105485-yoterada) の実践者が推奨する一般的なベスト プラクティスを見てみましょう。

| 項目 | 理由 |
|:---|:---|
| 最新モデルの評価 | 新世代のモデルは、機能や品質が向上している可能性があります。一方でコストが高くなる可能性もあります。影響を評価し移行の可否を検討します。 |
| 指示とコンテキストの分離 | 使用しているモデルやサービス提供者が、指示やプライマリコンテンツ、セカンダリコンテンツを明確に区別するために、「_区切り文字_」を定義しているか確認してください。これにより、モデルはトークンに対して重みをより正確に割り当てられます。 |
| 具体的かつ明確 | 目的のコンテキスト、結果、長さ、フォーマット、スタイルなどについての詳細を記入してください。これにより、回答の品質と一貫性の両方が向上します。再利用可能なテンプレートにレシピを取り込みます。 |
| 詳細に説明し、実例を示す | モデルは「示しながら教える」アプローチにより適切に応答する可能性があります。まずはゼロショット・アプローチからはじめます、最初は指示を出すだけで例を示さないでください。次にフューショット・アプローチで期待する出力例をいくつか提供し改善します。類推してください。|
| 手がかりを用いて出力を促進 | 回答の起点となる、いくつかの単語やフレーズを与え期待する結果を得てください。|
| ダブル・ダウン | 場合によっては、モデルに対して自身で反復する必要があります。メイン・コンテンツの前後で指示を出したり、指示やキュー（手がかり）を使ったりします。反復して検証し、何が機能するかを確認します。|
| 順序の重要性 | モデルに対する情報提示の順番は出力に影響を及ぼす場合があります。それが学習例の提示だとしても、最近の情報に過敏に影響を受ける認知バイアス (recency bias) によって影響します。（訳者追記：プロンプトの末尾にある情報が出力に大きな影響を与える場合がある）どの方法が最良かを見極めるために、異なる方法を試すのもお勧めします。|
| モデルに「代替案」を用意する | 何らかの理由でタスクを完了できない場合に備えて、モデルが提供できる「_代替の回答_」を用意してください。これにより、モデルが誤ったり、捏造した回答を生成する可能性を低減します。|

すべてのベストプラクティスに共通して、「_実際の効果はケース・バイ・ケース_」であると認識してください。モデルの種類、タスクの内容、専門分野によって結果は変わります。上記の指針を手始めに、ご自身にとって何が最も効果的かを見つけるために、試行錯誤を繰り返してください。新しいモデルやツールが登場するたびに、プロセスのスケーラビリティと回答の品質に注目し、プロンプト・エンジニアリングの手法をを継続的に再評価しましょう。

<!--
LESSON TEMPLATE:
このユニットは、可能であればコードチャレンジを提供するべきです。

CHALLENGE:
指示中には、コードコメントのみが含まれている Jupyter ノートブックへのリンクを提供（コード部分は空）。

SOLUTION:
実行可能なプロンプトが記入された、ノートブックのコピーへのリンクです。これは一つの例を示しています。
-->

## 課題  

おめでとうございます！レッスンの最後までたどり着きました！これから、実際の例を使って、いくつかの概念や技術を試す時が来ました！

課題では、対話式で取り組める演習問題がセットされた Jupyter Notebook を使用します。また、ご自身でアイデアや技術を検証するために、独自の Markdown やコードセルを Notebook に追加できます。

### 作業を開始するには、リポジトリをフォークてください  
  
- (推奨) GitHub Codespacesを起動  
- (代替案 1) リポジトリをローカル・デバイスにクローンして、ローカルの Docker Desktop で実行
- (代替案 2) 好みのノートブック実行環境でノートブックを開く  

### 次に、環境変数を設定してください

- リポジトリのルートにある `.env.copy` ファイルを `.env` にコピーし、`OPENAI_API_KEY` の値を入力してください。API キーは [OpenAI Dashboard](https://beta.openai.com/account/api-keys?WT.mc_id=academic-105485-yoterada) から取得できます。

### 次に、Jupyter Notebookを開いてください

- 使用する実行環境のカーネルを選択してください。オプション 1 や 2 を利用している場合は、devcontainer が提供する標準の Python 3.10.x カーネルを選んでください。

これで、演習を行う準備が整いました。この演習には _正解や不正解はありません_。与えられたモデルとアプリケーション・ドメインに対して、何が効果的かを試行錯誤しながら感覚を養ってください。

_このため、このレッスンにはコードの解答例は含まれていません。代わりに、ノートブックには 「My Solution」 と書かれた Markdown セルがあり、参考として出力例を示しています。_

 <!--
LESSON TEMPLATE:
このセクションをまとめと、自己学習のためのリソースを紹介して締めくくります
-->

## 知識チェック

以下のプロンプトの中で、適切なベストプラクティスに沿ったものはどれですか？

1. 赤い車の写真を画像を表示してください
2. 夕日が沈む崖のそばに駐車した、赤いボルボの XC90 モデルの画像を表示してください  
3. 赤いボルボの XC90 モデルの画像を表示してください

A: 2番が最良のプロンプトです。それは「何を」求めているのかの詳細を提供し、具体的な情報（任意の車ではなく、特定のメーカーとモデル）を含んでいる上、周囲の環境についても描写しています。次に良いのは3番で、これも詳細な記述が含まれています。

## 🚀 チャレンジ

プロンプトで 「キュー」のテクニックを利用してください。  
例文：「赤いボルボの車の画像を見せて、そして...」という文を完成させてください。どのような回答が返ってきますか？また、それをどう改善できますか？

## お疲れ様でした! 次のレッスンを続ける

プロンプト・エンジニアリングに関して、さらに概念をもっと深く学びたい方は、この話題に関する他の素晴らしい情報を見つけるために[継続的学習のページ](../../../13-continued-learning/README.md?WT.mc_id=academic-105485-yoterada)をご参照ください。

それでは、レッスン5に移り、[高度なプロンプト技術](../../../05-advanced-prompts/translations/ja-jp/README.md?WT.mc_id=academic-105485-yoterada)を見ていきましょう！
